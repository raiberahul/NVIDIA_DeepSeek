#!/usr/bin/env python3
"""
NVIDIA/DeepSeek Comprehensive Market Analysis Pipeline
-----------------------------------------------------
A unified script that performs:
1. Data collection (news, Reddit, stock prices)
2. Sentiment analysis
3. Statistical correlation
4. Automated PowerPoint reporting

Dependencies: pandas, numpy, textblob, yfinance, praw, requests, python-pptx, matplotlib
"""

import os
import time
import pandas as pd
import yfinance as yf
import requests
from textblob import TextBlob
from datetime import datetime
from pptx import Presentation
from pptx.util import Inches
import matplotlib.pyplot as plt
import io

# ======================
# CONFIGURATION
# ======================
CONFIG = {
    # API Keys (replace with your own)
    "gnews_api_key": "YOUR_GNEWS_KEY",
    "reddit_client_id": "YOUR_REDDIT_ID",
    "reddit_client_secret": "YOUR_REDDIT_SECRET",
    "alpha_vantage_key": "YOUR_ALPHA_VANTAGE_KEY",
    
    # Date range for analysis
    "start_date": "2025-01-20",
    "end_date": "2025-02-03",
    
    # Event date for focus analysis
    "event_date": "2025-01-27",
    
    # File paths
    "output_dir": "analysis_output",
    "stock_symbol": "NVDA"
}

# ======================
# DATA COLLECTION
# ======================
def fetch_stock_data():
    """Fetch historical stock prices using yfinance"""
    print("ðŸ“ˆ Fetching stock data...")
    data = yf.download(
        CONFIG["stock_symbol"],
        start=CONFIG["start_date"],
        end=CONFIG["end_date"],
        progress=False
    )
    data.reset_index(inplace=True)
    data['date'] = pd.to_datetime(data['Date']).dt.date
    return data[['date', 'Close', 'Volume']].rename(columns={'Close': 'price'})

def fetch_news_articles():
    """Fetch news articles from GNews API"""
    print("ðŸ“° Collecting news articles...")
    params = {
        "q": "(Nvidia OR NVDA) AND (AI OR DeepSeek)",
        "from": f"{CONFIG['start_date']}T00:00:00Z",
        "to": f"{CONFIG['end_date']}T23:59:59Z",
        "token": CONFIG["gnews_api_key"],
        "lang": "en",
        "max": 100
    }
    
    try:
        response = requests.get("https://gnews.io/api/v4/search", params=params)
        response.raise_for_status()
        articles = response.json().get("articles", [])
        
        # Process articles
        news_data = []
        for article in articles:
            pub_date = article.get("publishedAt", "")[:10]  # Extract YYYY-MM-DD
            if CONFIG["start_date"] <= pub_date <= CONFIG["end_date"]:
                news_data.append({
                    "date": pub_date,
                    "title": article.get("title", ""),
                    "source": article.get("source", {}).get("name", "Unknown"),
                    "content": article.get("content", "")[:500]  # First 500 chars
                })
        return pd.DataFrame(news_data)
    except Exception as e:
        print(f"Error fetching news: {e}")
        return pd.DataFrame()

# ======================
# DATA PROCESSING
# ======================
def add_sentiment(df, text_column='title'):
    """Add sentiment scores using TextBlob"""
    print("ðŸ§  Analyzing sentiment...")
    df['sentiment'] = df[text_column].apply(
        lambda x: TextBlob(str(x)).sentiment.polarity
    )
    return df

# ======================
# ANALYSIS
# ======================
def event_study_analysis(df):
    """Analyze sentiment around the event date"""
    print("ðŸ” Running event study...")
    event_date = pd.to_datetime(CONFIG["event_date"])
    window = df[
        (df["date"] >= event_date - pd.Timedelta(days=3)) & 
        (df["date"] <= event_date + pd.Timedelta(days=3))
    ]
    return window.groupby("date")["sentiment"].mean()

# ======================
# VISUALIZATION & REPORTING
# ======================
def create_presentation(results):
    """Generate PowerPoint report"""
    print("ðŸ“Š Creating presentation...")
    prs = Presentation()
    
    # Title Slide
    slide = prs.slides.add_slide(prs.slide_layouts[0])
    title = slide.shapes.title
    title.text = "NVIDIA DeepSeek Impact Analysis"
    
    # Add more slides with visualizations here
    # ... (additional presentation code from nvidia_deepseek_complete.py)
    
    # Save presentation
    os.makedirs(CONFIG["output_dir"], exist_ok=True)
    pptx_path = os.path.join(CONFIG["output_dir"], "analysis_report.pptx")
    prs.save(pptx_path)
    print(f"âœ… Presentation saved to {pptx_path}")

# ======================
# MAIN EXECUTION
# ======================
def main():
    start_time = time.time()
    
    # Create output directory
    os.makedirs(CONFIG["output_dir"], exist_ok=True)
    
    try:
        # Data Collection
        stock_data = fetch_stock_data()
        news_data = fetch_news_articles()
        
        # Data Processing
        merged_data = pd.merge(news_data, stock_data, on="date", how="left")
        analyzed_data = add_sentiment(merged_data)
        
        # Analysis
        event_results = event_study_analysis(analyzed_data)
        
        # Reporting
        create_presentation({
            "stock_data": stock_data,
            "sentiment_results": event_results
        })
        
        print(f"âœ¨ Analysis completed in {time.time()-start_time:.2f} seconds")
        
    except Exception as e:
        print(f"âŒ Error in pipeline: {str(e)}")

if __name__ == "__main__":
    main()
